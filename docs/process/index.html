<!doctype html>
<html><head><meta charset='utf-8'><title>EEG-FM Digest | About</title>
<link rel='stylesheet' href='../assets/style.css?v=20260225-1'></head><body>
<header class='site-shell'><div class='site-shell-inner'><div class='site-shell-top'><div class='site-brand'><p class='site-title'><a class='site-title-link' href='../index.html'>EEG Foundation Model Digest</a></p></div><nav class='site-nav'><a class='site-nav-link' href='../index.html'>Monthly Digest</a><a class='site-nav-link' href='../explore/index.html'>Search</a><a class='site-nav-link active' href='../process/index.html'>About</a><a class='site-nav-link site-nav-link-repo' href='https://github.com/iroblesrazzaq/EEG-FM-Digest' rel='noopener noreferrer' target='_blank'>GitHub Repo</a></nav></div><div class='site-shell-meta'><p class='site-byline'>by <strong>Ismael Robles-Razzaq</strong></p><div class='site-contact-links'><a class='contact-link' href='https://github.com/iroblesrazzaq' aria-label='GitHub profile' title='GitHub profile' rel='noopener noreferrer'><svg viewBox='0 0 24 24' aria-hidden='true'><path d='M12 2C6.477 2 2 6.489 2 12.018c0 4.424 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.009-.866-.014-1.7-2.782.605-3.369-1.344-3.369-1.344-.454-1.157-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.031 1.531 1.031.892 1.53 2.341 1.088 2.91.832.091-.647.349-1.088.635-1.338-2.221-.252-4.555-1.114-4.555-4.956 0-1.094.39-1.99 1.029-2.692-.103-.253-.446-1.272.098-2.651 0 0 .84-.269 2.75 1.028A9.564 9.564 0 0 1 12 6.844c.85.004 1.705.115 2.504.337 1.909-1.297 2.748-1.028 2.748-1.028.546 1.379.203 2.398.1 2.651.64.702 1.027 1.598 1.027 2.692 0 3.851-2.337 4.701-4.566 4.949.359.309.678.918.678 1.849 0 1.335-.012 2.413-.012 2.741 0 .269.18.58.688.482A10.022 10.022 0 0 0 22 12.018C22 6.489 17.523 2 12 2z'/></svg><span class='sr-only'>GitHub profile</span></a><a class='contact-link' href='https://iroblesrazzaq.github.io/' aria-label='Personal website' title='Personal website' rel='noopener noreferrer'><svg viewBox='0 0 24 24' aria-hidden='true'><path d='M12 2a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm7.93 9h-3.08a15.64 15.64 0 0 0-1.14-5.01A8.03 8.03 0 0 1 19.93 11zM12 4.06c1.12 1.3 2.05 3.7 2.4 6.94H9.6c.35-3.24 1.28-5.64 2.4-6.94zM4.07 13h3.08c.1 1.74.5 3.44 1.14 5.01A8.03 8.03 0 0 1 4.07 13zm3.08-2H4.07a8.03 8.03 0 0 1 4.22-5.01A15.64 15.64 0 0 0 7.15 11zM12 19.94c-1.12-1.3-2.05-3.7-2.4-6.94h4.8c-.35 3.24-1.28 5.64-2.4 6.94zM15.71 18.01c.64-1.57 1.04-3.27 1.14-5.01h3.08a8.03 8.03 0 0 1-4.22 5.01z'/></svg><span class='sr-only'>Personal website</span></a><a class='contact-link' href='https://www.linkedin.com/in/ismaelroblesrazzaq' aria-label='LinkedIn profile' title='LinkedIn profile' rel='noopener noreferrer'><svg viewBox='0 0 16 16' aria-hidden='true'><path d='M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.21c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.227 2.4 3.936c0 .694.521 1.248 1.327 1.248h.016zm4.908 8.21V9.359c0-.216.016-.432.079-.586.173-.431.568-.878 1.232-.878.869 0 1.216.663 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169H6.251c.03.678 0 7.225 0 7.225h2.4z'/></svg><span class='sr-only'>LinkedIn profile</span></a><a class='contact-link' href='mailto:ismaelroblesrazzaq@gmail.com' aria-label='Email ismaelroblesrazzaq@gmail.com' title='Email ismaelroblesrazzaq@gmail.com'><svg viewBox='0 0 16 16' aria-hidden='true'><path d='M0 4a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v8a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V4zm2-.5a.5.5 0 0 0-.5.5v.217l6.5 4.062 6.5-4.062V4a.5.5 0 0 0-.5-.5H2zm12.5 1.549-4.71 2.944 4.71 2.97V5.05zM14.247 12l-5.246-3.311-.734.458a.5.5 0 0 1-.53 0l-.734-.458L1.753 12h12.494zM1.5 10.964l4.71-2.97-4.71-2.944v5.914z'/></svg><span class='sr-only'>Email ismaelroblesrazzaq@gmail.com</span></a></div></div></div></header>
<main class='container process-page'>
<h1>About This Digest</h1>
<section class='process-content'>
<p>This digest serves as a monthly update on the current EEG foundation model literature. I built it so I can keep up to date with the latest EEG FM papers, mostly using Codex 5.3. The process is as follows:</p>
<ul><li>First we call the arXiv API to retrieve papers with EEG-FM-related terms in their title and abstract. This yielded me 492 candidate papers.</li><li>Then, I use an LLM on the title and abstract to triage all papers returned by the arXiv search. The model returns a decision (accept, reject, borderline), its confidence, and 2-4 reasons for its decision. 94 papers passed this step.</li><li>Finally, for all models accepted by the triage LLM, we download the pdf, extract text with PyMuPDF, and run a summary LLM where we extract a summary, bullet points, unique contribution, and tags.</li></ul>
<p>All triage and summary LLM calls through February 2026 use arcee-ai/trinity-large-preview:free (thanks to the Arcee AI team for making their model free on OpenRouter). For all previous papers (2021 - Jan 2026), running this whole process cost ~3 million tokens, so each accepted paper costs ~30,000 tokens (including averaged triage costs for papers that don&#x27;t pass). Crucially, this digest excludes models pretrained on data from one specific task and fine-tuned specifically for that same task - we define an EEG FM as a large model pretrained on EEG data, built with the potential and intention for broad transfer. I update the digest at least once a month, hopefully every week if I&#x27;m diligent.</p>
<h2>Limitations</h2>
<ul><li>Only checks paper on arXiv.</li><li>arXiv keyword search may miss papers.</li><li>Triage LLM could misclassify a paper.</li><li>Summary LLM is not an expert on the literature - one consequence is that it lacks the expertise to judge important and novel contributions, so it must rely on the paper to accurately self-identify novelty/importance.</li></ul>
<h2>arXiv Retrieval Keywords</h2>
<section class='prompt-details keyword-details'>
<p class='small'>Matching requires one EEG term plus one FM term set in title/abstract.</p>
<div class='keyword-grid'>
<section>
<p><strong>EEG term set</strong> (used in both queries)</p>
<ul><li><code>eeg</code></li><li><code>electroencephalograph*</code></li><li><code>brainwave*</code></li></ul>
</section>
<section>
<p><strong>FM term set A</strong></p>
<ul><li><code>&quot;foundation model&quot;</code></li><li><code>pretrain</code></li><li><code>pretrained</code></li><li><code>&quot;self-supervised&quot;</code></li><li><code>&quot;self supervised&quot;</code></li></ul>
</section>
<section>
<p><strong>FM term set B</strong></p>
<ul><li><code>&quot;representation learning&quot;</code></li><li><code>masked</code></li><li><code>transfer</code></li><li><code>generaliz*</code></li></ul>
</section>
</div>
</section>
<h2>LLM Prompts</h2>
<p>These are the full prompts used for each stage.</p>
<section class='prompt-details'>
<p><strong>Triage prompt</strong> (<code>prompts/triage.md</code>)</p>
<pre class='prompt-block'>You are a strict-but-recall-oriented classifier for whether an arXiv paper should be included in an EEG Foundation Model (EEG-FM) digest.

Inclusion criteria:
- Include only when EEG is a primary/central modality AND the paper clearly concerns EEG foundation models (EEG-FMs), i.e., pretrained reusable EEG representations/models intended for broad transfer.
- Include multimodal papers only when EEG is central (not incidental) and the pretrained transferable representation/model explicitly includes EEG as a core target modality.
- Include EEG-FM ecosystem papers (even without a new base model) when they clearly target EEG foundation models: benchmark/evaluation, adaptation/fine-tuning/post-training, alignment, scaling analysis, or systematic review/survey of EEG-FMs.

Exclude:
- EEG is peripheral/incidental.
- Generic EEG deep learning, SSL, transfer learning, domain adaptation, subject identification, or task-specific decoding work unless the abstract explicitly frames it as EEG foundation-model work.
- Purely supervised single-task EEG work with no FM/pretraining-for-broad-transfer framing.
- Non-EEG papers unless EEG is clearly central.
- Papers that claim &quot;pretraining&quot; but only for narrow within-task performance and do not present reusable foundation-model-style EEG representations.

You will be given only:
- title
- abstract

Output format (strict):
- Return exactly one JSON object.
- No markdown, no code fences, no surrounding text.
- No extra keys.
- Use exactly these keys: [&quot;decision&quot;,&quot;confidence&quot;,&quot;reasons&quot;]

Field requirements:
- decision: one of [&quot;accept&quot;,&quot;reject&quot;,&quot;borderline&quot;]
- confidence: number in [0,1]
- reasons: 2 to 4 short evidence-based strings grounded in provided title/abstract only

Decision guidance:
- accept only if the abstract provides clear positive evidence of EEG-FM relevance.
- borderline if EEG is central and FM relevance is plausible but ambiguous.
- reject otherwise.
- Do not accept based on weak proxies alone (e.g., &quot;deep learning&quot;, &quot;transfer learning&quot;, &quot;self-supervised&quot;) without explicit FM-style EEG evidence.

Input:
Title: {{TITLE}}
Abstract: {{ABSTRACT}}</pre>
</section>
<section class='prompt-details'>
<p><strong>Summary prompt</strong> (<code>prompts/summarize.md</code>)</p>
<pre class='prompt-block'>You are writing a deep structured digest summary for an EEG-FM paper.

Rules:
- Use ONLY the provided metadata/abstract/text fields (`fulltext` or `fulltext_slices`).
- Do NOT invent facts. If unknown, set null/unknown.
- Keep it concise and digest-oriented, but not shallow.
- Tagging rule: choose tags ONLY from `allowed_tags` in input JSON.
- For each tag category (`paper_type`, `backbone`, `objective`, `tokenization`, `topology`), output at most 2 tags.

Output MUST be valid JSON matching the PaperSummary schema (no markdown, no extra keys).
You MUST include every required field, even when unknown.
Copy these fields exactly from input JSON:
- `arxiv_id_base`
- `title`
- `published_date`
- `categories`

Required output keys checklist:
- `arxiv_id_base`, `title`, `published_date`, `categories`
- `paper_type`, `one_liner`, `detailed_summary`, `unique_contribution`, `key_points`
- `data_scale`, `method`, `evaluation`, `open_source`, `tags`, `limitations`
- `used_fulltext`, `notes`

Important disambiguation:
- `paper_type` is a SINGLE string from schema enum (`new_model|benchmark|survey|method|application|other`).
- `tags.paper_type` is an ARRAY chosen from `allowed_tags.paper_type`.
- For paper-type tag naming, use `new-model` (not `eeg-fm`).

What to focus on:
- unique_contribution: a single crisp sentence describing what is new.
- detailed_summary: 2-4 sentences that clearly explain:
  1) what the paper proposes,
  2) what is novel compared with typical prior work,
  3) what evidence is presented (dataset/task/result level) if available.
- key_points: 2-3 concise bullet-style points for UI display.
  The first bullet MUST state what the paper is, starting with paper type in natural wording, e.g.,
  &quot;New EEG foundation model: ...&quot;
  Do not use templated labels like &quot;What it is:&quot;, &quot;Core method/evidence:&quot;, or &quot;Main practical takeaway:&quot;.
  Remaining bullet(s) should cover method novelty and strongest concrete evidence/result.
  Avoid copying `unique_contribution` verbatim; partial semantic overlap is allowed.
  Also avoid repeating the same opening clause between `key_points` and `unique_contribution`.
- data_scale: datasets, subjects, eeg_hours, channels (if present)
- method: architecture + objective + pretraining + finetuning (if present)
- evaluation: tasks/benchmarks/headline results (if present)
- open_source: code/weights/license if explicitly mentioned

Strict typing constraints:
- `data_scale.subjects`, `data_scale.eeg_hours`, `data_scale.channels` must be number or null (never strings like &quot;10k+&quot; or &quot;64ch&quot;).
- `key_points` must have 2-3 items.
- `limitations` must have 2-8 items.
- `tags.&lt;category&gt;` arrays must contain only values from `allowed_tags.&lt;category&gt;`, max 2 values each.
- `used_fulltext` must be boolean.
- `notes` must be a string.

Input:
{{INPUT_JSON}}</pre>
</section>
</section>
</main>
</body></html>

<!doctype html>
<html><head><meta charset='utf-8'><title>About</title>
<link rel='stylesheet' href='../assets/style.css'></head><body>
<header class='site-shell'><div class='site-shell-inner'><div class='site-brand'><p class='site-title'><a class='site-title-link' href='../index.html'>EEG Foundation Model Digest</a></p></div><nav class='site-nav'><a class='site-nav-link' href='../index.html'>Monthly Digest</a><a class='site-nav-link' href='../explore/index.html'>Explore</a><a class='site-nav-link active' href='../process/index.html'>About</a></nav></div></header>
<main class='container process-page'>
<h1>About This Digest</h1>
<section class='process-content'>
<p>This digest serves as a monthly update on the current EEG foundation model literature. I built it so I can keep up to date with the latest EEG FM papers, mostly using Codex 5.3. The process is as follows:</p>
<ul><li>First we call the arXiv API to retrieve papers with EEG-FM-related terms in their title and abstract.</li><li>Then, we use an LLM on the title and abstract to triage all papers returned by the arXiv search. The model returns a decision (accept, reject, borderline), its confidence, and 2-4 reasons for its decision.</li><li>Next, for all models accepted by the triage LLM, we download the pdf, extract text with PyMuPDF, and run a summary LLM where we extract a summary, bullet points, unique contribution, and tags.</li></ul>
<p>All triage and summary LLM calls through February 2026 use arcee-ai/trinity-large-preview:free.</p>
<h2>arXiv Retrieval Keywords</h2>
<section class='prompt-details keyword-details'>
<p class='small'>Matching requires one EEG term plus one FM term set in title/abstract.</p>
<div class='keyword-grid'>
<section>
<p><strong>EEG term set</strong> (used in both queries)</p>
<ul><li><code>eeg</code></li><li><code>electroencephalograph*</code></li><li><code>brainwave*</code></li></ul>
</section>
<section>
<p><strong>FM term set A</strong></p>
<ul><li><code>&quot;foundation model&quot;</code></li><li><code>pretrain</code></li><li><code>pretrained</code></li><li><code>&quot;self-supervised&quot;</code></li><li><code>&quot;self supervised&quot;</code></li></ul>
</section>
<section>
<p><strong>FM term set B</strong></p>
<ul><li><code>&quot;representation learning&quot;</code></li><li><code>masked</code></li><li><code>transfer</code></li><li><code>generaliz*</code></li></ul>
</section>
</div>
</section>
<h2>LLM Prompts</h2>
<p>These are the full prompts used for each stage.</p>
<section class='prompt-details'>
<p><strong>Triage prompt</strong> (<code>prompts/triage.md</code>)</p>
<pre class='prompt-block'>You are a strict-but-recall-oriented classifier for whether an arXiv paper should be included in an EEG Foundation Model (EEG-FM) digest.

Inclusion criteria:
- Include only when EEG is a primary/central modality AND the paper clearly concerns EEG foundation models (EEG-FMs), i.e., pretrained reusable EEG representations/models intended for broad transfer.
- Include multimodal papers only when EEG is central (not incidental) and the pretrained transferable representation/model explicitly includes EEG as a core target modality.
- Include EEG-FM ecosystem papers (even without a new base model) when they clearly target EEG foundation models: benchmark/evaluation, adaptation/fine-tuning/post-training, alignment, scaling analysis, or systematic review/survey of EEG-FMs.

Exclude:
- EEG is peripheral/incidental.
- Generic EEG deep learning, SSL, transfer learning, domain adaptation, subject identification, or task-specific decoding work unless the abstract explicitly frames it as EEG foundation-model work.
- Purely supervised single-task EEG work with no FM/pretraining-for-broad-transfer framing.
- Non-EEG papers unless EEG is clearly central.
- Papers that claim &quot;pretraining&quot; but only for narrow within-task performance and do not present reusable foundation-model-style EEG representations.

You will be given only:
- title
- abstract

Output format (strict):
- Return exactly one JSON object.
- No markdown, no code fences, no surrounding text.
- No extra keys.
- Use exactly these keys: [&quot;decision&quot;,&quot;confidence&quot;,&quot;reasons&quot;]

Field requirements:
- decision: one of [&quot;accept&quot;,&quot;reject&quot;,&quot;borderline&quot;]
- confidence: number in [0,1]
- reasons: 2 to 4 short evidence-based strings grounded in provided title/abstract only

Decision guidance:
- accept only if the abstract provides clear positive evidence of EEG-FM relevance.
- borderline if EEG is central and FM relevance is plausible but ambiguous.
- reject otherwise.
- Do not accept based on weak proxies alone (e.g., &quot;deep learning&quot;, &quot;transfer learning&quot;, &quot;self-supervised&quot;) without explicit FM-style EEG evidence.

Input:
Title: {{TITLE}}
Abstract: {{ABSTRACT}}</pre>
</section>
<section class='prompt-details'>
<p><strong>Summary prompt</strong> (<code>prompts/summarize.md</code>)</p>
<pre class='prompt-block'>You are writing a deep structured digest summary for an EEG-FM paper.

Rules:
- Use ONLY the provided metadata/abstract/text fields (`fulltext` or `fulltext_slices`).
- Do NOT invent facts. If unknown, set null/unknown.
- Keep it concise and digest-oriented, but not shallow.
- Tagging rule: choose tags ONLY from `allowed_tags` in input JSON.
- For each tag category (`paper_type`, `backbone`, `objective`, `tokenization`, `topology`), output at most 2 tags.

Output MUST be valid JSON matching the PaperSummary schema (no markdown, no extra keys).
You MUST include every required field, even when unknown.
Copy these fields exactly from input JSON:
- `arxiv_id_base`
- `title`
- `published_date`
- `categories`

Required output keys checklist:
- `arxiv_id_base`, `title`, `published_date`, `categories`
- `paper_type`, `one_liner`, `detailed_summary`, `unique_contribution`, `key_points`
- `data_scale`, `method`, `evaluation`, `open_source`, `tags`, `limitations`
- `used_fulltext`, `notes`

Important disambiguation:
- `paper_type` is a SINGLE string from schema enum (`new_model|benchmark|survey|method|application|other`).
- `tags.paper_type` is an ARRAY chosen from `allowed_tags.paper_type`.
- For paper-type tag naming, use `new-model` (not `eeg-fm`).

What to focus on:
- unique_contribution: a single crisp sentence describing what is new.
- detailed_summary: 2-4 sentences that clearly explain:
  1) what the paper proposes,
  2) what is novel compared with typical prior work,
  3) what evidence is presented (dataset/task/result level) if available.
- key_points: 2-3 concise bullet-style points for UI display.
  The first bullet MUST state what the paper is, starting with paper type in natural wording, e.g.,
  &quot;New EEG foundation model: CEReBrO ...&quot;
  Do not use templated labels like &quot;What it is:&quot;, &quot;Core method/evidence:&quot;, or &quot;Main practical takeaway:&quot;.
  Remaining bullet(s) should cover method novelty and strongest concrete evidence/result.
  Avoid copying `unique_contribution` verbatim; partial semantic overlap is allowed.
  Also avoid repeating the same opening clause between `key_points` and `unique_contribution`.
- data_scale: datasets, subjects, eeg_hours, channels (if present)
- method: architecture + objective + pretraining + finetuning (if present)
- evaluation: tasks/benchmarks/headline results (if present)
- open_source: code/weights/license if explicitly mentioned

Strict typing constraints:
- `data_scale.subjects`, `data_scale.eeg_hours`, `data_scale.channels` must be number or null (never strings like &quot;10k+&quot; or &quot;64ch&quot;).
- `key_points` must have 2-3 items.
- `limitations` must have 2-8 items.
- `tags.&lt;category&gt;` arrays must contain only values from `allowed_tags.&lt;category&gt;`, max 2 values each.
- `used_fulltext` must be boolean.
- `notes` must be a string.

Input:
{{INPUT_JSON}}</pre>
</section>
</section>
</main>
</body></html>

{
  "month": "2025-01",
  "papers": [
    {
      "arxiv_id": "2501.10885v4",
      "arxiv_id_base": "2501.10885",
      "authors": [
        "Alexandru Dimofte",
        "Glenn Anta Bucagu",
        "Thorir Mar Ingolfsson",
        "Xiaying Wang",
        "Andrea Cossettini",
        "Luca Benini",
        "Yawei Li"
      ],
      "categories": [
        "cs.LG"
      ],
      "links": {
        "abs": "http://arxiv.org/abs/2501.10885v4",
        "pdf": "https://arxiv.org/pdf/2501.10885v4"
      },
      "published_date": "2025-01-18",
      "summary": {
        "arxiv_id_base": "2501.10885",
        "categories": [
          "cs.LG"
        ],
        "data_scale": {
          "channels": null,
          "datasets": [
            "TUEG (20,000+ hours, 10,000+ subjects)"
          ],
          "eeg_hours": 20000.0,
          "subjects": 10000.0
        },
        "detailed_summary": "CEReBrO introduces a compact EEG foundation model that addresses key limitations in current EEG signal modeling approaches. The model employs a novel tokenization scheme that represents EEG signals at per-channel patch granularity, enabling granular modeling of temporal dynamics within each channel. The core innovation is an alternating attention mechanism that jointly models intra-channel temporal dynamics and inter-channel spatial correlations, achieving 2x speed improvement with 6x less memory compared to standard self-attention. The model is pre-trained on over 20,000 hours of publicly available scalp EEG recordings from more than 10,000 unique subjects with diverse channel configurations. CEReBrO demonstrates state-of-the-art performance on emotion detection and seizure detection tasks while maintaining competitive performance in anomaly classification and gait prediction, validating its effectiveness and efficiency for deployment on resource-constrained devices.",
        "evaluation": {
          "benchmarks": [
            "SEED dataset",
            "Neonate dataset",
            "TUAB dataset",
            "MoBI dataset"
          ],
          "headline_results": [
            "68.21% accuracy, 0.6845 F1 score (85M parameters)",
            "0.875 AUROC (85M parameters)",
            "81.67% accuracy, 0.9049 AUPR (85M parameters)",
            "0.3118 RÂ² score, 0.1209 RMSE (85M parameters)"
          ],
          "tasks": [
            "Emotion detection",
            "Seizure detection",
            "Anomaly classification",
            "Gait prediction"
          ]
        },
        "key_points": [
          "New EEG foundation model: CEReBrO introduces a compact encoder-only architecture with alternating attention for efficient spatio-temporal EEG modeling",
          "Alternating attention innovation: Jointly models intra-channel temporal dynamics and inter-channel spatial correlations, achieving 2x speed improvement with 6x less memory than standard self-attention",
          "State-of-the-art performance: Sets new benchmarks in emotion detection and seizure detection while maintaining competitive performance in anomaly classification and gait prediction"
        ],
        "limitations": [
          "Performance on spectrograms slightly worse than waveforms with alternating attention",
          "Maximum channel limit of 64 channels due to padding mechanism",
          "No explicit comparison with other efficient attention alternatives like low-rank approximations",
          "Limited ablation studies on different attention mechanisms for spectrogram representations"
        ],
        "method": {
          "architecture": "Transformer encoder with alternating attention mechanism",
          "finetuning": "Fine-tuning with mean pooling for classification",
          "objective": "Masked autoencoding on raw EEG waveforms",
          "pretraining": "Pre-training on 20,000+ hours of publicly available scalp EEG recordings"
        },
        "notes": "manual_resummary_prompt_update;input_mode=fulltext;prompt_tokens=16807",
        "one_liner": "New compact EEG foundation model with alternating attention mechanism for efficient spatio-temporal modeling",
        "open_source": {
          "code_url": null,
          "license": null,
          "weights_url": null
        },
        "paper_type": "new_model",
        "published_date": "2025-01-18",
        "tags": {
          "backbone": [
            "transformer"
          ],
          "objective": [
            "masked-reconstruction"
          ],
          "paper_type": [
            "new-model"
          ],
          "tokenization": [
            "time-patch"
          ],
          "topology": [
            "channel-flexible"
          ]
        },
        "title": "CEReBrO: Compact Encoder for Representations of Brain Oscillations Using Efficient Alternating Attention",
        "unique_contribution": "Novel alternating attention mechanism that efficiently captures both temporal and spatial EEG dynamics while reducing computational requirements by 6x in memory and 2x in runtime compared to standard self-attention",
        "used_fulltext": true
      },
      "summary_failed_reason": null,
      "title": "CEReBrO: Compact Encoder for Representations of Brain Oscillations Using Efficient Alternating Attention",
      "triage": {
        "confidence": 0.9,
        "decision": "accept",
        "reasons": [
          "The paper introduces CEReBrO, a new small EEG foundation model.",
          "It explicitly mentions 'pre-trained reusable EEG representations/models intended for broad transfer' by using 'large unlabeled datasets' and setting 'new benchmarks in emotion detection and seizure detection tasks'.",
          "The model is designed to address limitations in current EEG signal modeling and model size, aiming for efficiency and reproducibility.",
          "The abstract clearly states the goal of creating a 'Compact Encoder for Representations of Brain Oscillations' which aligns with the definition of an EEG foundation model."
        ]
      }
    }
  ],
  "stats": {
    "accepted": 1,
    "candidates": 9,
    "summarized": 1
  },
  "top_picks": [
    "2501.10885"
  ]
}
